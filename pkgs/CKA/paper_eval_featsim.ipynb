{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from copy import deepcopy\n",
    "sys.path.append(\"../../\")\n",
    "from utility import utils as uu\n",
    "sys.path.append(\"../FTE/\")\n",
    "import pkgs.FTE.finetuning_tasks as ftasks\n",
    "import numpy as np, random, PIL\n",
    "import torch, torchvision.transforms.functional as ttf\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "random.seed(69)\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_paths(cfg_name):\n",
    "\n",
    "    with open(cfg_name, \"r\") as o:\n",
    "        lines = o.readlines()\n",
    "    for line in lines:\n",
    "        if line[0:10] == \"model_path\":\n",
    "            pt_model_path = line.split(\": \")[-1].split(\"\\\"\")[1]\n",
    "        if line[0:4] == \"name\":\n",
    "            ft_model_path = \"../../logs_and_checkpoints/finetuning/\"+line.split(\": \")[-1].split(\"\\\"\")[1]+\"/finetuned_model.tar\"\n",
    "\n",
    "    return pt_model_path, ft_model_path\n",
    "\n",
    "def get_pt_model(cfg_name):\n",
    "\n",
    "    class Arg:\n",
    "        pass\n",
    "\n",
    "    # Argument parsing like in finetune.py\n",
    "    config = uu.yaml_config_hook(cfg_name)\n",
    "    args = Arg()\n",
    "    for k, v in config.items():\n",
    "        setattr(args, k, v)\n",
    "\n",
    "    # Defaults like in finetune.py\n",
    "    args.save_path = os.path.join(\"../../logs_and_checkpoints/finetuning/\", args.name)\n",
    "    if not \"debug\" in vars(args):\n",
    "        args.debug = False\n",
    "    if not \"test_nan_inf\" in vars(args):\n",
    "        args.test_nan_inf = True\n",
    "    if not os.path.exists(args.save_path):\n",
    "        os.makedirs(args.save_path)\n",
    "\n",
    "    if isinstance(vars(args).get(\"w_l\", None), list):\n",
    "        args.w_l = torch.Tensor(args.w_l)\n",
    "    else:\n",
    "        args.w_l = None\n",
    "    if isinstance(vars(args).get(\"w_m\", None), list):\n",
    "        args.w_m = torch.Tensor(args.w_m)\n",
    "    else:\n",
    "        args.w_m = None\n",
    "\n",
    "    # Seeding like in finetune.py\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "    \n",
    "    # dont need multiple GPUs for this, trick ftasks into not using DataParallel\n",
    "    args.device = None\n",
    "\n",
    "    # get PT model\n",
    "    #print(args.task)\n",
    "    pt_model = ftasks.model_from_task(args, tf = None)\n",
    "    \n",
    "    return pt_model\n",
    "\n",
    "def get_ft_model(cfg_name, pt_model):\n",
    "\n",
    "    _, ft_model_path = get_model_paths(cfg_name)\n",
    "    ft_model = deepcopy(pt_model)\n",
    "    sd = torch.load(ft_model_path, map_location = torch.device(\"cpu\"))\n",
    "    dk = []\n",
    "    for key in sd:\n",
    "        if any([x in key for x in [\"head\", \"loss\", \"PLACEHOLDER\"]]):\n",
    "            dk.append(key)\n",
    "    for key in dk:\n",
    "        del sd[key]\n",
    "    ft_model.load_state_dict(sd, strict = False)\n",
    "    \n",
    "    return ft_model\n",
    "\n",
    "def get_ref_batch():\n",
    "\n",
    "    def load_any(file):\n",
    "        if file.endswith(\".npy\"):\n",
    "            array = np.load(file)\n",
    "            tensor = torch.tensor(array, dtype = torch.float32)\n",
    "            tensor = torch.stack([tensor]*3, dim = 0)\n",
    "            tensor = ttf.resize(tensor, [256, 256])\n",
    "        elif file.endswith(\".JPEG\"):\n",
    "            with PIL.Image.open(file) as f:\n",
    "                array = np.array(f)\n",
    "            tensor = torch.tensor(array, dtype = torch.float32)\n",
    "            tensor = tensor.moveaxis(-1, 0)\n",
    "            tensor = ttf.resize(tensor, [256, 256])\n",
    "        else:\n",
    "            NotImplementedError\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    # ref image lists\n",
    "    f = 0\n",
    "    i1k_images = uu.getFileList(\"../../datasets/imagenet-1k/ILSVRC/Data/CLS-LOC/val\", \".jpeg\")\n",
    "    rad_images = uu.getFileList(\"../../datasets/medical_2D/test_wo6\", \".npy\")\n",
    "\n",
    "    # randomly choose from each list\n",
    "    ref_images = []\n",
    "    random.shuffle(i1k_images)\n",
    "    random.shuffle(rad_images)\n",
    "    # cant use too many images - constrained by memory (for small GPUs) and also size of matrix (cub)\n",
    "    ref_images.extend(i1k_images[0:2])\n",
    "    #ref_images.extend(rad_images[0:2])\n",
    "\n",
    "    # load and stack\n",
    "    ref_images = torch.stack([load_any(image) for image in tqdm(ref_images)], dim = 0)\n",
    "    \n",
    "    return ref_images\n",
    "\n",
    "# Forward hook for activations\n",
    "activations = {}\n",
    "layer_weights = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref batch\n",
    "ref_batch = get_ref_batch()\n",
    "print(ref_batch.size())\n",
    "ref_batch = ref_batch.to(device)\n",
    "\n",
    "# dummy targets\n",
    "dummy_targets = torch.tensor([0])\n",
    "dummy_targets = dummy_targets.to(device)\n",
    "\n",
    "# dummy loss criterion\n",
    "class DummyLossC(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DummyLossC, self).__init__()\n",
    "\n",
    "    def forward(self, *args):\n",
    "        return torch.tensor([0], device = device)\n",
    "DummyLoss = DummyLossC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_activations_from_model(model, name):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if \"LiTS\" in name or \"BraTS\" in name:\n",
    "            model.unet.backbone.conv1.register_forward_hook(get_activation(name+\"_L1\"))\n",
    "            model.unet.backbone.layer1[0].conv1.register_forward_hook(get_activation(name+\"_L2\"))\n",
    "            model.unet.backbone.layer1[0].conv2.register_forward_hook(get_activation(name+\"_L3\"))\n",
    "        else:\n",
    "            model.encoder.conv1.register_forward_hook(get_activation(name+\"_L1\"))\n",
    "            model.encoder.layer1[0].conv1.register_forward_hook(get_activation(name+\"_L2\"))\n",
    "            model.encoder.layer1[0].conv2.register_forward_hook(get_activation(name+\"_L3\"))\n",
    "        model.loss_criterion = DummyLoss\n",
    "        _ = model(ref_batch, dummy_targets)\n",
    "        for L in [\"_L1\", \"_L2\", \"_L3\"]:\n",
    "            activations[name+L] = activations[name+L].moveaxis(1, -1).flatten(end_dim = -2)#.to(dtype = torch.float16)#.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_layer_weights_from_model(model, name):\n",
    "\n",
    "    # Get weights\n",
    "    if \"LiTS\" in name or \"BraTS\" in name:\n",
    "        lw1 = model.unet.backbone.conv1.weight\n",
    "        lw2 = model.unet.backbone.layer1[0].conv1.weight\n",
    "        lw3 = model.unet.backbone.layer1[0].conv2.weight\n",
    "    else:\n",
    "        lw1 = model.encoder.conv1.weight\n",
    "        lw2 = model.encoder.layer1[0].conv1.weight\n",
    "        lw3 = model.encoder.layer1[0].conv2.weight\n",
    "\n",
    "    # Flatten all except channel dimension\n",
    "    layer_weights[name+\"_L1\"] = lw1.moveaxis(1, -1).flatten(end_dim = -2)\n",
    "    layer_weights[name+\"_L2\"] = lw2.moveaxis(1, -1).flatten(end_dim = -2)\n",
    "    layer_weights[name+\"_L3\"] = lw3.moveaxis(1, -1).flatten(end_dim = -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../../pkgs/FTE/config/\"\n",
    "\n",
    "es = [\"E1\"] #, \"E2\", \"E3\", \"E4\"] <- We could do this all experiments, but the comparison does not make much sense for E4, and E2/E3 are not that accurate to begin with, plus E3 has no uncertainty estimation runs\n",
    "\n",
    "pt_extract = {\n",
    "    \"PT_Scratch\": \"../../pkgs/FTE/config/E1/PT_Scratch_FT_R.yaml\",\n",
    "    \"PT_SimCLR_I1k\": \"../../pkgs/FTE/config/E1/PT_SimCLR_I1k_FT_R.yaml\",\n",
    "    \"PT_SimCLR_RF\": \"../../pkgs/FTE/config/E1/PT_SimCLR_RF_FT_R.yaml\",\n",
    "    \"PT_SimCLR_R\": \"../../pkgs/FTE/config/E1/PT_SimCLR_R_FT_R.yaml\",\n",
    "}\n",
    "runs = {e: [f \n",
    "            for f in uu.getFileList(base_path+e, \".yaml\") \n",
    "            if not any([x in f for x in [\"_tr.yaml\", \"_testing.yaml\", \"_PVOC\"]])] # ignore any logs of stuff outside the paper\n",
    "            for e in es}\n",
    "\n",
    "def ft_cfg_names_to_name(cfg_name):\n",
    "    split = cfg_name.split(\"/\")\n",
    "    filename = split[-2]+\"/\"+split[-1][:-5]\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model states after pretraining\n",
    "for name, run_cfg in tqdm(pt_extract.items()):\n",
    "    pt_model_path, _ = get_model_paths(run_cfg)\n",
    "    pt_model = get_pt_model(run_cfg)\n",
    "    pt_model = pt_model.to(device)\n",
    "    pt_model.eval()\n",
    "    collect_activations_from_model(pt_model, name) # Not actually used\n",
    "    collect_layer_weights_from_model(pt_model, name)\n",
    "\n",
    "# model states after finetuning\n",
    "for e in es:\n",
    "    for run_cfg in tqdm(runs[e]):\n",
    "        name = ft_cfg_names_to_name(run_cfg)\n",
    "        #print(name)\n",
    "        _, ft_model_path = get_model_paths(run_cfg)\n",
    "        pt_model = get_pt_model(run_cfg)\n",
    "        ft_model = get_ft_model(run_cfg, pt_model)\n",
    "        ft_model = ft_model.to(device)\n",
    "        ft_model.eval()\n",
    "        collect_activations_from_model(ft_model, name) # Not actually used\n",
    "        collect_layer_weights_from_model(ft_model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpuCKA import CudaCKA\n",
    "CCKA_inst = CudaCKA(device)\n",
    "import matplotlib, matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_names = {\n",
    "    \"PT_Scratch\": \"No pretraining ('Scratch')\",\n",
    "    \"PT_SimCLR_I1k\": \"Pretrained on ImageNet-1k\",\n",
    "    \"PT_SimCLR_R\": \"Pretrained on RadNet-1.28M\",\n",
    "    \"PT_SimCLR_RF\": \"Pretrained on RadNet-12M\",\n",
    "    \"E1/PT_Scratch_FT_BraTS\": \"PT Scratch, FT BraTS\",\n",
    "    \"E1/PT_Scratch_FT_CX8\": \"PT Scratch, FT ChestX-ray8\",\n",
    "    \"E1/PT_Scratch_FT_I1k\": \"PT Scratch, FT ImageNet-1k\",\n",
    "    \"E1/PT_Scratch_FT_LiTS\": \"PT Scratch, FT LiTS\",\n",
    "    \"E1/PT_Scratch_FT_R\": \"PT Scratch, FT RadNet-1.28M\",\n",
    "    \"E1/PT_SimCLR_I1k_FT_BraTS\": \"PT ImageNet-1k, FT BraTS\",\n",
    "    \"E1/PT_SimCLR_I1k_FT_CX8\": \"PT ImageNet-1k, FT ChestX-ray8\",\n",
    "    \"E1/PT_SimCLR_I1k_FT_I1k\": \"PT ImageNet-1k, FT ImageNet-1k\",\n",
    "    \"E1/PT_SimCLR_I1k_FT_LiTS\": \"PT ImageNet-1k, FT LiTS\",\n",
    "    \"E1/PT_SimCLR_I1k_FT_R\": \"PT ImageNet-1k, FT RadNet-1.28M\",\n",
    "    \"E1/PT_SimCLR_R_FT_BraTS\": \"PT RadNet-1.28M, FT BraTS\",\n",
    "    \"E1/PT_SimCLR_R_FT_CX8\": \"PT RadNet-1.28M, FT ChestX-ray8\",\n",
    "    \"E1/PT_SimCLR_R_FT_I1k\": \"PT RadNet-1.28M, FT ImageNet-1k\",\n",
    "    \"E1/PT_SimCLR_R_FT_LiTS\": \"PT RadNet-1.28M, FT LiTS\",\n",
    "    \"E1/PT_SimCLR_R_FT_R\": \"PT RadNet-1.28M, FT RadNet-1.28M\",\n",
    "    \"E1/PT_SimCLR_RF_FT_BraTS\": \"PT RadNet-12M, FT BraTS\",\n",
    "    \"E1/PT_SimCLR_RF_FT_CX8\": \"PT RadNet-12M, FT ChestX-ray8\",\n",
    "    \"E1/PT_SimCLR_RF_FT_I1k\": \"PT RadNet-12M, FT ImageNet-1k\",\n",
    "    \"E1/PT_SimCLR_RF_FT_LiTS\": \"PT RadNet-12M, FT LiTS\",\n",
    "    \"E1/PT_SimCLR_RF_FT_R\": \"PT RadNet-12M, FT RadNet-1.28M\",\n",
    "    \"FT_BraTS\": \"Finetuned on BraTS\", \n",
    "    \"FT_CX8\": \"Finetuned on ChestX-ray8\", \n",
    "    \"FT_I1k\": \"Finetuned on ImageNet-1k\", \n",
    "    \"FT_LiTS\": \"Finetuned on LiTS\", \n",
    "    \"FT_R\": \"Finetuned on RadNet-1.28M\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variations(name):\n",
    "    if any([name.endswith(x) for x in [\"_L1\", \"_L2\", \"_L3\"]]):\n",
    "        l = name[-3:]\n",
    "        n = name[:-3]\n",
    "    else:\n",
    "        l = \"\"\n",
    "        n = name\n",
    "    variations = [n+l]\n",
    "    variations.extend([n+x+l for x in [\"_f1\", \"_f2\", \"_f3\"]])\n",
    "    return variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Reuse\n",
    "pt_acts = {name: act for name, act in layer_weights.items() if not \"_FT_\" in name}\n",
    "pt_names = [\"PT_Scratch\", \"PT_SimCLR_I1k\", \"PT_SimCLR_R\", \"PT_SimCLR_RF\"]\n",
    "ft_names = [\"FT_BraTS\", \"FT_CX8\", \"FT_I1k\", \"FT_LiTS\", \"FT_R\"]\n",
    "\n",
    "results_means = {}\n",
    "results_stds = {}\n",
    "for pn in tqdm(pt_names):\n",
    "    for L in [\"_L1\", \"_L2\", \"_L3\"]:\n",
    "        for fn in tqdm(ft_names):\n",
    "            n1 = pn+L\n",
    "            n2 = get_variations(\"E1/\"+pn+\"_\"+fn+L)\n",
    "            sim = np.array([\n",
    "                CCKA_inst.kernel_CKA(pt_acts[n1], layer_weights[n2v]).detach().cpu().numpy()\n",
    "                for n2v in n2\n",
    "                ])\n",
    "            mean = np.mean(sim)\n",
    "            std = np.std(sim)\n",
    "            results_means[(pn, fn, L)] = mean\n",
    "            results_stds[(pn, fn, L)] = std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in results_means.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Reuse plots\n",
    "ttc_palette = {\n",
    "    \"PT_Scratch\": \"gray\",\n",
    "    \"PT_SimCLR_I1k\": \"red\",\n",
    "    \"PT_SimCLR_R\": \"cornflowerblue\",\n",
    "    \"PT_SimCLR_RF\": \"blue\"\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 3, ncols = 2, figsize = (16, 10))\n",
    "for k, task in enumerate([\"FT_BraTS\", \"FT_CX8\", \"FT_I1k\", \"FT_LiTS\", \"FT_R\"]):\n",
    "    ax = axes[k // 2, k % 2]\n",
    "    plt.rcParams.update({'axes.titlesize': 'x-large'})\n",
    "    plt.rcParams.update({'axes.labelsize': 'large'})\n",
    "    ax.set_title(f\"{screen_names[task]}\")\n",
    "    ax.set_xticks([1.5, 4, 6.5])\n",
    "    ax.set_xticklabels([\"Conv1 weights\", \"Conv2 weights\", \"Conv3 weights\"])\n",
    "    ax.set_ylabel(\"Feature Reuse\")\n",
    "    ax.set_xlim(0, 8)\n",
    "    ax.set_ylim(\n",
    "        min([results_means[(pn, task, L)] - 0.01 for pn in pt_names for L in [\"_L1\", \"_L2\", \"_L3\"]]),\n",
    "        max([results_means[(pn, task, L)] + results_stds[(pn, task, L)] + 0.01 for pn in pt_names for L in [\"_L1\", \"_L2\", \"_L3\"]]))\n",
    "    for j, L in enumerate([\"_L1\", \"_L2\", \"_L3\"]):\n",
    "        bars = [results_means[(pn, task, L)] for pn in pt_names]\n",
    "        errs = [results_stds[(pn, task, L)] for pn in pt_names]\n",
    "        if j == 2:\n",
    "            labels = [screen_names[pn] for pn in pt_names]\n",
    "        else:\n",
    "            labels = [\"\", \"\", \"\", \"\"]\n",
    "        colors = [ttc_palette[pn] for pn in pt_names]\n",
    "        pos = [0.5*i + 2.5*j + 0.5 for i in range(len(pt_names))]\n",
    "        for l in range(len(pos)):\n",
    "            ax.bar(\n",
    "                x = pos[l],\n",
    "                height = bars[l],\n",
    "                width = 0.5,\n",
    "                yerr = errs[l],\n",
    "                capsize = 10,\n",
    "                label = labels[l],\n",
    "                color = colors[l],\n",
    "                align = \"edge\",\n",
    "                edgecolor = \"k\",\n",
    "                linewidth = 1\n",
    "            )\n",
    "ax = axes[2, 1]\n",
    "task = \"Average across tasks\"\n",
    "plt.rcParams.update({'axes.titlesize': 'x-large'})\n",
    "plt.rcParams.update({'axes.labelsize': 'large'})\n",
    "ax.set_title(task)\n",
    "ax.set_xticks([1.5, 4, 6.5])\n",
    "ax.set_xticklabels([\"Conv1 weights\", \"Conv2 weights\", \"Conv3 weights\"])\n",
    "ax.set_ylabel(\"Feature Reuse\")\n",
    "ax.set_xlim(0, 8)\n",
    "for pn in pt_names:\n",
    "    for L in [\"_L1\", \"_L2\", \"_L3\"]:\n",
    "        results_means[(pn, \"avg\", L)] = np.mean([results_means[(pn, task, L)] for task in [\"FT_BraTS\", \"FT_CX8\", \"FT_I1k\", \"FT_LiTS\", \"FT_R\"]])\n",
    "        results_stds[(pn, \"avg\", L)] = 1/5 * np.sqrt(sum([results_stds[(pn, task, L)]**2 for task in [\"FT_BraTS\", \"FT_CX8\", \"FT_I1k\", \"FT_LiTS\", \"FT_R\"]]))\n",
    "ax.set_ylim(\n",
    "    min([results_means[(pn, \"avg\", L)] - 0.01 for pn in pt_names for L in [\"_L1\", \"_L2\", \"_L3\"]]),\n",
    "    max([results_means[(pn, \"avg\", L)] + results_stds[(pn, \"avg\", L)] + 0.01 for pn in pt_names for L in [\"_L1\", \"_L2\", \"_L3\"]]))\n",
    "for j, L in enumerate([\"_L1\", \"_L2\", \"_L3\"]):\n",
    "    bars = [results_means[(pn, \"avg\", L)] for pn in pt_names]\n",
    "    errs = [results_stds[(pn, \"avg\", L)] for pn in pt_names]\n",
    "    if j == 2:\n",
    "        labels = [screen_names[pn] for pn in pt_names]\n",
    "    else:\n",
    "        labels = [\"\", \"\", \"\", \"\"]\n",
    "    colors = [ttc_palette[pn] for pn in pt_names]\n",
    "    pos = [0.5*i + 2.5*j + 0.5 for i in range(len(pt_names))]\n",
    "    for l in range(len(pos)):\n",
    "        ax.bar(\n",
    "            x = pos[l],\n",
    "            height = bars[l],\n",
    "            width = 0.5,\n",
    "            yerr = errs[l],\n",
    "            capsize = 10,\n",
    "            label = labels[l],\n",
    "            color = colors[l],\n",
    "            align = \"edge\",\n",
    "            edgecolor = \"k\",\n",
    "            linewidth = 1\n",
    "        )\n",
    "#for task, ax in zip(\n",
    "#    [\"Finetuned on BraTS\",\n",
    "#     \"Finetuned on ChestX-Ray8\",\n",
    "#     \"Finetuned on ImageNet-1k\",\n",
    "#     \"Finetuned on LiTS\",\n",
    "#     \"Finetuned on BraTS\",\n",
    "#     \"Average across tasks\"],\n",
    "#    axes.flatten()):\n",
    "#    extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "#    fig.savefig(f\"./figures/Feature_Reuse_Task_{task}.svg\", format = \"svg\", bbox_inches = extent)\n",
    "handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, bbox_to_anchor = [0.97, 0.0], prop = {'size': 15}, ncol = 4)\n",
    "fig.subplots_adjust(hspace = 1.0, wspace = 1.0)\n",
    "fig.tight_layout()\n",
    "#axes[2, 1].set_visible(False)\n",
    "\n",
    "plt.savefig(f\"./figures/Feature_Reuse_E1.svg\", format = \"svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual figures\n",
    "\n",
    "for k, task in enumerate([\"FT_BraTS\", \"FT_CX8\", \"FT_I1k\", \"FT_LiTS\", \"FT_R\"]):\n",
    "    fig = plt.figure(figsize = (8, 5))\n",
    "    plt.rcParams.update({'axes.titlesize': 'x-large'})\n",
    "    plt.rcParams.update({'axes.labelsize': 'large'})\n",
    "    plt.title(f\"{screen_names[task]}\")\n",
    "    plt.xticks([1.5, 4, 6.5], [\"Conv1 weights\", \"Conv2 weights\", \"Conv3 weights\"])\n",
    "    plt.ylabel(\"Feature Reuse\")\n",
    "    plt.xlim(0, 8)\n",
    "    plt.ylim(\n",
    "        min([results_means[(pn, task, L)] - 0.01 for pn in pt_names for L in [\"_L1\", \"_L2\", \"_L3\"]]),\n",
    "        max([results_means[(pn, task, L)] + results_stds[(pn, task, L)] + 0.01 for pn in pt_names for L in [\"_L1\", \"_L2\", \"_L3\"]])\n",
    "        )\n",
    "    for j, L in enumerate([\"_L1\", \"_L2\", \"_L3\"]):\n",
    "        bars = [results_means[(pn, task, L)] for pn in pt_names]\n",
    "        errs = [results_stds[(pn, task, L)] for pn in pt_names]\n",
    "        labels = [screen_names[pn] for pn in pt_names]\n",
    "        colors = [ttc_palette[pn] for pn in pt_names]\n",
    "        pos = [0.5*i + 2.5*j + 0.5 for i in range(len(pt_names))]\n",
    "        plt.bar(\n",
    "            x = pos,\n",
    "            height = bars,\n",
    "            width = 0.5,\n",
    "            yerr = errs,\n",
    "            capsize = 10,\n",
    "            label = labels,\n",
    "            color = colors,\n",
    "            align = \"edge\",\n",
    "            edgecolor = \"k\",\n",
    "            linewidth = 1\n",
    "        )\n",
    "    plt.savefig(f\"./figures/Feature_Reuse_{task}.svg\", format = \"svg\", bbox_inches = \"tight\")\n",
    "\n",
    "plt.figure(figsize = (8, 5))\n",
    "plt.rcParams.update({'axes.titlesize': 'x-large'})\n",
    "plt.rcParams.update({'axes.labelsize': 'large'})\n",
    "plt.title(\"Average across tasks\")\n",
    "plt.xticks([1.5, 4, 6.5], [\"Conv1 weights\", \"Conv2 weights\", \"Conv3 weights\"])\n",
    "plt.ylabel(\"Feature Reuse\")\n",
    "plt.xlim(0, 8)\n",
    "for pn in pt_names:\n",
    "    for L in [\"_L1\", \"_L2\", \"_L3\"]:\n",
    "        results_means[(pn, \"avg\", L)] = np.mean([results_means[(pn, task, L)] for task in [\"FT_BraTS\", \"FT_CX8\", \"FT_I1k\", \"FT_LiTS\", \"FT_R\"]])\n",
    "        results_stds[(pn, \"avg\", L)] = 1/5 * np.sqrt(sum([results_stds[(pn, task, L)]**2 for task in [\"FT_BraTS\", \"FT_CX8\", \"FT_I1k\", \"FT_LiTS\", \"FT_R\"]]))\n",
    "plt.ylim(\n",
    "    min([results_means[(pn, \"avg\", L)] - 0.01 for pn in pt_names for L in [\"_L1\", \"_L2\", \"_L3\"]]),\n",
    "    max([results_means[(pn, \"avg\", L)] + results_stds[(pn, \"avg\", L)] + 0.01 for pn in pt_names for L in [\"_L1\", \"_L2\", \"_L3\"]])\n",
    "    )\n",
    "for j, L in enumerate([\"_L1\", \"_L2\", \"_L3\"]):\n",
    "    bars = [results_means[(pn, \"avg\", L)] for pn in pt_names]\n",
    "    errs = [results_stds[(pn, \"avg\", L)] for pn in pt_names]\n",
    "    colors = [ttc_palette[pn] for pn in pt_names]\n",
    "    pos = [0.5*i + 2.5*j + 0.5 for i in range(len(pt_names))]\n",
    "    for l in range(len(pos)):\n",
    "        if j == 2:\n",
    "            plt.bar(\n",
    "                x = pos[l],\n",
    "                height = bars[l],\n",
    "                width = 0.5,\n",
    "                yerr = errs[l],\n",
    "                capsize = 10,\n",
    "                label = labels[l],\n",
    "                color = colors[l],\n",
    "                align = \"edge\",\n",
    "                edgecolor = \"k\",\n",
    "                linewidth = 1\n",
    "            )\n",
    "        else:\n",
    "            plt.bar(\n",
    "                x = pos[l],\n",
    "                height = bars[l],\n",
    "                width = 0.5,\n",
    "                yerr = errs[l],\n",
    "                capsize = 10,\n",
    "                color = colors[l],\n",
    "                align = \"edge\",\n",
    "                edgecolor = \"k\",\n",
    "                linewidth = 1\n",
    "            )\n",
    "plt.savefig(f\"./figures/Feature_Reuse_Average.svg\", format = \"svg\", bbox_inches = \"tight\")\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "legend = fig.legend(handles, labels, bbox_to_anchor = [0.97, 0.0], prop = {'size': 15}, ncol = 4)\n",
    "bbox  = legend.get_window_extent()\n",
    "bbox = bbox.from_extents(*(bbox.extents + np.array([-5, -5, 5, 5])))\n",
    "bbox = bbox.transformed(legend.figure.dpi_scale_trans.inverted())\n",
    "legend.figure.savefig(f\"./figures/Feature_Reuse_legend.svg\", format = \"svg\", dpi = \"figure\", bbox_inches = bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Uniqueness\n",
    "\n",
    "def feature_uniqueness(acts, axis = 0, n_split = 8):\n",
    "\n",
    "    # Even splits are necessary for unbiased results\n",
    "    if acts.size()[axis] % n_split != 0:\n",
    "        raise ValueError(f\"PT activations with shape {acts.size()} must be evenly splittable along axis {axis} using n_split = {n_split}!\")\n",
    "\n",
    "    # Test n_split times each\n",
    "    results = []\n",
    "    r = acts.size()[axis] // n_split\n",
    "    for s1 in range(n_split):\n",
    "        for s2 in range(n_split):\n",
    "\n",
    "            # Tests are symmetrical, no need to do double the work\n",
    "            if s1 >= s2:\n",
    "                continue\n",
    "            \n",
    "            # Get CKA similarity\n",
    "            sim = CCKA_inst.kernel_CKA(\n",
    "                torch.index_select(acts, dim = axis, index = torch.tensor([x for x in range(r*s1, r*(s1+1))]).to(\"cuda:0\")),\n",
    "                torch.index_select(acts, dim = axis, index = torch.tensor([x for x in range(r*s2, r*(s2+1))]).to(\"cuda:0\"))\n",
    "                ).detach().cpu().numpy()\n",
    "            \n",
    "            # Append uniqueness value\n",
    "            results.append(1 - sim)\n",
    "\n",
    "    return np.mean(results), np.std(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueness_means = {}\n",
    "uniqueness_stds = {}\n",
    "\n",
    "pt_names = [\"PT_Scratch\", \"PT_SimCLR_I1k\", \"PT_SimCLR_R\", \"PT_SimCLR_RF\"]\n",
    "\n",
    "for pn in tqdm(pt_names):\n",
    "    for L in tqdm([\"_L1\", \"_L2\", \"_L3\"]):\n",
    "        u_ms, u_ss = [], []\n",
    "        #for variation in get_variations(pn+L) get the uniqueness of that variation, not applicable to pt_acts\n",
    "        u_m, u_s = feature_uniqueness(layer_weights[pn+L], axis = 0, n_split = 8)\n",
    "        u_ms.append(u_m)\n",
    "        u_ss.append(u_s)\n",
    "        uniqueness_means[(pn, L)] = np.mean(u_ms)\n",
    "        uniqueness_stds[(pn, L)] = np.sqrt(sum([x**2 for x in u_ss]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in uniqueness_means.items():\n",
    "    print(f\"{k}: {uniqueness_means[k]} +/- {uniqueness_stds[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 4.5))\n",
    "plt.xticks(ticks = [1.5, 4, 6.5], labels = [\"Conv1 weights\", \"Conv2 weights\", \"Conv3 weights\"])\n",
    "plt.yticks(ticks = [0, 0.2, 0.4, 0.6, 0.8, 1.0], labels = [0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "plt.ylabel(\"Feature Uniqueness\")\n",
    "plt.xlim(0, 8)\n",
    "plt.ylim(\n",
    "    #min([uniqueness_means[(pn, L)] - 0.01 for pn in pt_names for L in [\"_L1\", \"_L2\", \"_L3\"]]),\n",
    "    0,\n",
    "    #max([uniqueness_means[(pn, L)] + uniqueness_stds[(pn, L)] + 0.01 for pn in pt_names for L in [\"_L1\", \"_L2\", \"_L3\"]]))\n",
    "    1)\n",
    "plt.rcParams.update({'axes.titlesize': 'x-large'})\n",
    "plt.rcParams.update({'axes.labelsize': 'large'})\n",
    "for j, L in enumerate([\"_L1\", \"_L2\", \"_L3\"]):\n",
    "    bars = [uniqueness_means[(pn, L)] for pn in pt_names]\n",
    "    errs = [uniqueness_stds[(pn, L)] for pn in pt_names]\n",
    "    if j == 2:\n",
    "        labels = [screen_names[pn] for pn in pt_names]\n",
    "    else:\n",
    "        labels = [\"\", \"\", \"\", \"\"]\n",
    "    colors = [ttc_palette[pn] for pn in pt_names]\n",
    "    pos = [0.5*i + 2.5*j + 0.5 for i in range(len(pt_names))]\n",
    "    for l in range(len(pos)):\n",
    "        plt.bar(\n",
    "            x = pos[l],\n",
    "            height = bars[l],\n",
    "            width = 0.5,\n",
    "            yerr = errs[l],\n",
    "            capsize = 10,\n",
    "            label = labels[l],\n",
    "            color = colors[l],\n",
    "            align = \"edge\",\n",
    "            edgecolor = \"k\",\n",
    "            linewidth = 1\n",
    "            )\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figures/uniqueness.svg\", format = \"svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Who knew what?\" plots\n",
    "\n",
    "def get_testing_equipment(cfg_name):\n",
    "\n",
    "    class Arg:\n",
    "        pass\n",
    "\n",
    "    # Argument parsing like in finetune.py\n",
    "    config = uu.yaml_config_hook(cfg_name)\n",
    "    args = Arg()\n",
    "    for k, v in config.items():\n",
    "        setattr(args, k, v)\n",
    "\n",
    "    # Defaults like in finetune.py\n",
    "    args.save_path = os.path.join(\"../../logs_and_checkpoints/finetuning/\", args.name)\n",
    "    if not \"debug\" in vars(args):\n",
    "        args.debug = False\n",
    "    if not \"test_nan_inf\" in vars(args):\n",
    "        args.test_nan_inf = True\n",
    "    if not os.path.exists(args.save_path):\n",
    "        os.makedirs(args.save_path)\n",
    "\n",
    "    if isinstance(vars(args).get(\"w_l\", None), list):\n",
    "        args.w_l = torch.Tensor(args.w_l)\n",
    "    else:\n",
    "        args.w_l = None\n",
    "    if isinstance(vars(args).get(\"w_m\", None), list):\n",
    "        args.w_m = torch.Tensor(args.w_m)\n",
    "    else:\n",
    "        args.w_m = None\n",
    "\n",
    "    # Seeding like in finetune.py\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "    \n",
    "    args.opmode = \"disk\"\n",
    "    args.verbose = False\n",
    "    \n",
    "    dataset, model, _, _, _ = ftasks.finetuning_task(args, manager = None)\n",
    "    _, ft_model_path = get_model_paths(cfg_name)\n",
    "    sd = torch.load(ft_model_path, map_location = args.device)\n",
    "    model.module.load_state_dict(sd, strict = True)\n",
    "    model.to(args.device)\n",
    "\n",
    "    return dataset, model, args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_codes = {\n",
    "    \"PT_Scratch\": 1,\n",
    "    \"PT_SimCLR_I1k\": 2,\n",
    "    \"PT_SimCLR_R\": 4,\n",
    "    \"PT_SimCLR_RF\": 8\n",
    "}\n",
    "pt_codes_inv = {v: k for k, v in pt_codes.items()}\n",
    "\n",
    "def test_everything(dataset, model, args, memory):\n",
    "\n",
    "    dataset.set_state(\"test\")\n",
    "    dataset.set_used_subset(\"test\")\n",
    "    model.eval()\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, num_workers = 8, batch_size = 256, shuffle = True)\n",
    "\n",
    "    for step, (data, idxs, targets) in tqdm(enumerate(loader), total=(len(dataset.subsets[\"test\"])//256)+1):\n",
    "\n",
    "        # To device\n",
    "        data = data.to(device = device)\n",
    "        idxs = idxs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Do model calculation\n",
    "        with torch.cuda.amp.autocast(enabled = True), torch.no_grad():\n",
    "            preds, _ = model(data, targets)\n",
    "            pc = torch.argmax(preds, dim=1).flatten()\n",
    "        for i in idxs[pc == targets]:\n",
    "            i = i.item()\n",
    "            if i in memory:\n",
    "                memory[i] += pt_codes[args.pt]\n",
    "            else:\n",
    "                memory[i] = pt_codes[args.pt]\n",
    "        for i in idxs[pc != targets]:\n",
    "            i = i.item()\n",
    "            if not i in memory:\n",
    "                memory[i] = 0\n",
    "\n",
    "def test_everything_lits(dataset, model, args, memory):\n",
    "\n",
    "    dataset.set_state(\"test\")\n",
    "    dataset.set_used_subset(\"test\")\n",
    "    model.eval()\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, num_workers = 8, batch_size = 256, shuffle = True)\n",
    "\n",
    "    memory[\"indices\"] = {}\n",
    "    for step, (data, idxs, targets) in tqdm(enumerate(loader), total=(len(dataset.subsets[\"test\"])//256)+1):\n",
    "\n",
    "        # To device\n",
    "        data = data.to(device = device)\n",
    "        idxs = idxs.to(device)\n",
    "        targets = [target_mask.to(device) for target_mask in targets]\n",
    "        \n",
    "        # Do model calculation\n",
    "        with torch.cuda.amp.autocast(enabled = True), torch.no_grad():\n",
    "            preds, _ = model(data, targets)\n",
    "            pc = torch.argmax(preds, dim=1)\n",
    "\n",
    "            all_targets = [torch.ones_like(targets[0]).to(targets[0].device)]\n",
    "            all_targets.extend(targets)\n",
    "            ct = torch.squeeze(2 - torch.argmax(torch.stack(tensors = all_targets[::-1], dim = 1), dim = 1))\n",
    "            hits = ((pc == ct) * (ct != 0)).to(torch.int8) * pt_codes[args.pt]\n",
    "            hits -= (ct == 0).to(torch.int8)\n",
    "\n",
    "        memory[\"indices\"][step] = idxs\n",
    "        if step in memory:\n",
    "            memory[step] += hits\n",
    "            memory[step] = torch.clamp(memory[step], -1, None)\n",
    "        else:\n",
    "            memory[step] = hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_models = {\n",
    "    \"I1k\":{\n",
    "        \"PT_Scratch\": \"../../pkgs/FTE/config/E1/PT_Scratch_FT_I1k.yaml\",\n",
    "        \"PT_SimCLR_I1k\": \"../../pkgs/FTE/config/E1/PT_SimCLR_I1k_FT_I1k.yaml\",\n",
    "        \"PT_SimCLR_R\": \"../../pkgs/FTE/config/E1/PT_SimCLR_R_FT_I1k.yaml\",\n",
    "        \"PT_SimCLR_RF\": \"../../pkgs/FTE/config/E1/PT_SimCLR_RF_FT_I1k.yaml\"\n",
    "    },\n",
    "    \"R\":{\n",
    "        \"PT_Scratch\": \"../../pkgs/FTE/config/E1/PT_Scratch_FT_R.yaml\",\n",
    "        \"PT_SimCLR_I1k\": \"../../pkgs/FTE/config/E1/PT_SimCLR_I1k_FT_R.yaml\",\n",
    "        \"PT_SimCLR_R\": \"../../pkgs/FTE/config/E1/PT_SimCLR_R_FT_R.yaml\",\n",
    "        \"PT_SimCLR_RF\": \"../../pkgs/FTE/config/E1/PT_SimCLR_RF_FT_R.yaml\"\n",
    "    },\n",
    "    \"LiTS\":{\n",
    "        \"PT_Scratch\": \"../../pkgs/FTE/config/E1/PT_Scratch_FT_LiTS.yaml\",\n",
    "        \"PT_SimCLR_I1k\": \"../../pkgs/FTE/config/E1/PT_SimCLR_I1k_FT_LiTS.yaml\",\n",
    "        \"PT_SimCLR_R\": \"../../pkgs/FTE/config/E1/PT_SimCLR_R_FT_LiTS.yaml\",\n",
    "        \"PT_SimCLR_RF\": \"../../pkgs/FTE/config/E1/PT_SimCLR_RF_FT_LiTS.yaml\"\n",
    "    },\n",
    "    \"I1k_L\":{\n",
    "        \"PT_SimCLR_I1k\": \"../../pkgs/FTE/config/E4/PT_SimCLR_I1k_FT_I1k_lineval.yaml\",\n",
    "        \"PT_SimCLR_R\": \"../../pkgs/FTE/config/E4/PT_SimCLR_R_FT_I1k_lineval.yaml\",\n",
    "        \"PT_SimCLR_RF\": \"../../pkgs/FTE/config/E4/PT_SimCLR_RF_FT_I1k_lineval.yaml\"\n",
    "    },\n",
    "    \"R_L\":{\n",
    "        \"PT_SimCLR_I1k\": \"../../pkgs/FTE/config/E4/PT_SimCLR_I1k_FT_R_lineval.yaml\",\n",
    "        \"PT_SimCLR_R\": \"../../pkgs/FTE/config/E4/PT_SimCLR_R_FT_R_lineval.yaml\",\n",
    "        \"PT_SimCLR_RF\": \"../../pkgs/FTE/config/E4/PT_SimCLR_RF_FT_R_lineval.yaml\"\n",
    "    },\n",
    "    \"LiTS_L\":{\n",
    "        \"PT_SimCLR_I1k\": \"../../pkgs/FTE/config/E4/PT_SimCLR_I1k_FT_LiTS_lineval.yaml\",\n",
    "        \"PT_SimCLR_R\": \"../../pkgs/FTE/config/E4/PT_SimCLR_R_FT_LiTS_lineval.yaml\",\n",
    "        \"PT_SimCLR_RF\": \"../../pkgs/FTE/config/E4/PT_SimCLR_RF_FT_LiTS_lineval.yaml\"\n",
    "    }\n",
    "}\n",
    "memory = {\"I1k\":{}, \"R\":{}, \"LiTS\":{}, \"I1k_L\":{}, \"R_L\":{}, \"LiTS_L\":{}}\n",
    "\n",
    "for group in ft_models:\n",
    "    for pn, cfg in ft_models[group].items():\n",
    "        dataset, model, args = get_testing_equipment(cfg)\n",
    "\n",
    "        args.pt = pn\n",
    "        torch.manual_seed(args.seed)\n",
    "        np.random.seed(args.seed)\n",
    "        random.seed(args.seed)\n",
    "        if \"LiTS\" in group:\n",
    "            test_everything_lits(dataset, model, args, memory[group])\n",
    "        else:\n",
    "            test_everything(dataset, model, args, memory[group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_rolls(num, chances):\n",
    "    cval = 1\n",
    "    if num > 0:\n",
    "        for c in [8, 4, 2, 1]:\n",
    "            if num >= c:\n",
    "                cval *= chances.get(pt_codes_inv[c], 0)\n",
    "                num -= c\n",
    "            else:\n",
    "                cval *= (1 - chances.get(pt_codes_inv[c], 0))\n",
    "    if cval == 1:\n",
    "        return math.prod([1 - chance for chance in list(chances.values())])\n",
    "    else:\n",
    "        return cval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who_knows_what_c = {x: plt.cm.tab20(x) for x in range(16)}\n",
    "who_knows_what_names = {\n",
    "    0: \"No predictors\",\n",
    "    1: \"Scratch (S)\",\n",
    "    2: \"ImageNet-1k (I)\",\n",
    "    3: \"S, I\",\n",
    "    4: \"RadNet-1.28M (R)\",\n",
    "    5: \"S, R\",\n",
    "    6: \"I, R\",\n",
    "    7: \"S, I, R\",\n",
    "    8: \"RadNet-12M (R12M)\",\n",
    "    9: \"S, R12M\",\n",
    "    10: \"I, R12M\",\n",
    "    11: \"S, I, R12M\",\n",
    "    12: \"R, R12M\",\n",
    "    13: \"S, R, R12M\",\n",
    "    14: \"I, R, R12M\",\n",
    "    15: \"S, I, R, R12M\"\n",
    "}\n",
    "group_screen_names = {\n",
    "    \"I1k\": \"Finetuning on ImageNet-1k\",\n",
    "    \"R\": \"Finetuning on RadNet-1.28M\",\n",
    "    \"LiTS\": \"Finetuning on LiTS\",\n",
    "    \"I1k_L\": \"Linear evaluation on ImageNet-1k\",\n",
    "    \"R_L\": \"Linear evaluation on RadNet-1.28M\",\n",
    "    \"LiTS_L\": \"Linear evaluation on LiTS\"\n",
    "}\n",
    "\n",
    "for group in ft_models:\n",
    "\n",
    "    chances = {}\n",
    "    expected = {}\n",
    "\n",
    "    for pn, cfg in ft_models[group].items():\n",
    "        log_loc = \"/\".join(cfg.split(\"/\")[-2:])[:-5]+\"/test.log\"\n",
    "        log_base = \"../../logs_and_checkpoints/finetuning/\"\n",
    "        with open(log_base+log_loc, \"r\") as o:\n",
    "            lines = o.readlines()\n",
    "        acc = lines[1].split(\",\")[0]\n",
    "        chances[pn] = float(acc)\n",
    "\n",
    "    for x in range(16):\n",
    "        expected[x] = rec_rolls(x, chances)\n",
    "\n",
    "    print(f\"Task: {group}\")\n",
    "    if \"LiTS\" in group:\n",
    "        vals = torch.concat([t.flatten() for t in memory[group].values() if not isinstance(t, dict)]).cpu().numpy()\n",
    "    else:\n",
    "        vals = list(memory[group].values())\n",
    "    c = Counter(vals)\n",
    "    sum_test = sum(list([v for k, v in c.items() if k != -1])) # should be 25k for I/R and 3038*256*256 * a few percent for LiTS\n",
    "    for k in range(16):\n",
    "        if not k in c:\n",
    "            c[k] = 0\n",
    "    for k, v in sorted(c.items()):\n",
    "        if k == -1:\n",
    "            continue\n",
    "        print(f\"{k}: {v} +/- {np.sqrt(v)} ({v/sum_test * 100:.3f}%), expected {expected[k]*sum_test}\")\n",
    "\n",
    "    fig = plt.figure(figsize = (8, 5))\n",
    "    # Results\n",
    "    plt.bar(\n",
    "        x = [p*1.25 for p in range(16)],\n",
    "        height = [v/sum_test for k, v in sorted(c.items()) if k != -1],\n",
    "        width = 0.5,\n",
    "        align = \"center\",\n",
    "        yerr = [np.sqrt(v)/sum_test for k, v in sorted(c.items()) if k != -1], # assume a poisson error for counts\n",
    "        capsize = 5,\n",
    "        color = [who_knows_what_c[k] for k, v in sorted(c.items()) if k != -1],\n",
    "        edgecolor = \"k\",\n",
    "        linewidth = 1\n",
    "    )\n",
    "    # Fully random expectation\n",
    "    plt.bar(\n",
    "        x = [p*1.25+0.5 for p in range(16)],\n",
    "        height = [expected[k] for k, v in sorted(c.items()) if k != -1],\n",
    "        width = 0.5,\n",
    "        align = \"center\",\n",
    "        color = [who_knows_what_c[k] for k, v in sorted(c.items()) if k != -1],\n",
    "        edgecolor = \"k\",\n",
    "        linewidth = 1,\n",
    "        hatch = \"XX\"\n",
    "    )\n",
    "    # Custom\n",
    "    plt.bar(\n",
    "        x = [22, 23.25, 24.5, 25.75],\n",
    "        height = [\n",
    "            sum([c[x] for x in [2, 3, 10, 11]]) / sum_test, # I + !R\n",
    "            sum([c[x] for x in [4, 5, 12, 13]]) / sum_test, # R + !I\n",
    "            sum([c[x] for x in [2, 3, 6, 7]])   / sum_test, # I + !R12M\n",
    "            sum([c[x] for x in [8, 9, 12, 13]]) / sum_test  # R12M + !I\n",
    "        ],\n",
    "        yerr = [\n",
    "            np.sqrt(sum([c[y] for y in x]))/sum_test\n",
    "            for x in [\n",
    "                [2, 3, 10, 11],\n",
    "                [4, 5, 12, 13], \n",
    "                [2, 3, 6, 7], \n",
    "                [8, 9, 12, 13]\n",
    "                ]\n",
    "            ],\n",
    "        capsize = 5,\n",
    "        width = 0.5,\n",
    "        align = \"center\",\n",
    "        color = [\"lightcoral\", \"cornflowerblue\", \"red\", \"blue\"],\n",
    "        edgecolor = \"k\",\n",
    "        linewidth = 1\n",
    "    )\n",
    "    print([\n",
    "            sum([c[x] for x in [2, 3, 10, 11]]) / sum_test, # I + !R\n",
    "            sum([c[x] for x in [4, 5, 12, 13]]) / sum_test, # R + !I\n",
    "            sum([c[x] for x in [2, 3, 6, 7]])   / sum_test, # I + !R12M\n",
    "            sum([c[x] for x in [8, 9, 12, 13]]) / sum_test  # R12M + !I\n",
    "        ])\n",
    "    print([\n",
    "            np.sqrt(sum([c[y] for y in x]))/sum_test\n",
    "            for x in [\n",
    "                [2, 3, 10, 11],\n",
    "                [4, 5, 12, 13], \n",
    "                [2, 3, 6, 7], \n",
    "                [8, 9, 12, 13]\n",
    "                ]\n",
    "            ]) # DEBUG\n",
    "    # Custom, random expectation\n",
    "    plt.bar(\n",
    "        x = [22.5, 23.75, 25, 26.25],\n",
    "        height = [\n",
    "            sum([expected[x] for x in [2, 3, 10, 11]]), # I + !R\n",
    "            sum([expected[x] for x in [4, 5, 12, 13]]), # R + !I\n",
    "            sum([expected[x] for x in [2, 3, 6, 7]])  , # I + !R12M\n",
    "            sum([expected[x] for x in [8, 9, 12, 13]])  # R12M + !I\n",
    "        ],\n",
    "        capsize = 5,\n",
    "        width = 0.5,\n",
    "        align = \"center\",\n",
    "        color = [\"lightcoral\", \"cornflowerblue\", \"red\", \"blue\"],\n",
    "        edgecolor = \"k\",\n",
    "        linewidth = 1,\n",
    "        hatch = \"XX\"\n",
    "    )\n",
    "    ticks = [p*1.25 for p in range(16)]\n",
    "    ticks.extend([22, 23.25, 24.5, 25.75])\n",
    "    ticklabels = [who_knows_what_names[k] for k, v in sorted(c.items()) if k != -1]\n",
    "    ticklabels.extend([\"I, ¬R\", \"R, ¬I\", \"I, ¬R12M\", \"R12M, ¬I\"])\n",
    "    plt.xticks(ticks = ticks, labels = ticklabels)\n",
    "    fig.autofmt_xdate(rotation = 45)\n",
    "    plt.ylabel(\"Fraction of correct predictions\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.gca().yaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "    ylow = {\n",
    "        \"I1k\": 8e-3,\n",
    "        \"R\": 1e-4,\n",
    "        \"LiTS\": 1e-5,\n",
    "        \"I1k_L\": 1e-2,\n",
    "        \"R_L\": 1e-4,\n",
    "        \"LiTS_L\": 1e-5\n",
    "    }\n",
    "    plt.vlines(20.625, ylow[group], 1, \"k\", \"--\")\n",
    "    plt.ylim(ylow[group], 1)\n",
    "    plt.title(f\"Task: {group_screen_names[group]}\")\n",
    "    plt.savefig(f\"./figures/wkw_{group}_summary.svg\", format = \"svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_diff = 0\n",
    "max_step = 0\n",
    "max_x = 0\n",
    "diff_images = []\n",
    "for step, images in memory[\"LiTS_L\"].items():\n",
    "    if not isinstance(images, dict):\n",
    "        for x in range(images.size()[0]):\n",
    "            sum_I = sum(torch.sum(images[x, :, :] == n) for n in [2, 3, 6, 7])\n",
    "            sum_R12 = sum(torch.sum(images[x, :, :] == n) for n in [8, 9, 12, 13])\n",
    "            diff = sum_R12 - sum_I\n",
    "            if diff > 200:\n",
    "                diff_images.append((step, x, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in diff_images:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where does ImageNet fail while RadNet-X does not?\n",
    "\n",
    "#sample_step, sample_x = 0, 247 # <- border\n",
    "#sample_step, sample_x = 1, 200 # <- border, low contrast in border region\n",
    "#sample_step, sample_x = 7, 175 # <- insular\n",
    "sample_step, sample_x = 9, 173 # <- semi-insular, low contrast\n",
    "\n",
    "test_set_id = memory[\"LiTS_L\"][\"indices\"][sample_step][sample_x]\n",
    "example_image_id = dataset.subsets[\"test\"][test_set_id]\n",
    "example_image, _, example_target = dataset._load(example_image_id)\n",
    "example_image = example_image.to(torch.float32).cpu().numpy()\n",
    "example_image -= np.min(example_image)\n",
    "example_image /= np.max(example_image)\n",
    "example_target_liver = example_target[0].to(torch.uint8).cpu().numpy()[0, ::-1, :]\n",
    "example_target_liver = np.stack(\n",
    "    [\n",
    "        np.zeros_like(example_target_liver),\n",
    "        example_target_liver * 255,\n",
    "        np.zeros_like(example_target_liver),\n",
    "        example_target_liver * 100\n",
    "    ],\n",
    "    axis = -1\n",
    ")\n",
    "example_target_lesion = example_target[1].to(torch.uint8).cpu().numpy()[0, ::-1, :]\n",
    "example_target_lesion = np.stack(\n",
    "    [\n",
    "        example_target_lesion * 255,\n",
    "        np.zeros_like(example_target_lesion),\n",
    "        np.zeros_like(example_target_lesion),\n",
    "        example_target_lesion * 100\n",
    "    ],\n",
    "    axis = -1\n",
    ")\n",
    "\n",
    "# empty\n",
    "plt.figure()\n",
    "plt.imshow(example_image[::-1, ::-1])\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(f\"./figures/wkw_{group}_{sample_step}_{sample_x}_base.png\", dpi = 600)\n",
    "\n",
    "# ground truth\n",
    "plt.figure()\n",
    "plt.imshow(example_image[::-1, ::-1])\n",
    "plt.imshow(example_target_liver[:, ::-1])\n",
    "plt.imshow(example_target_lesion[:, ::-1])\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(f\"./figures/wkw_{group}_{sample_step}_{sample_x}_gt.png\", dpi = 600)\n",
    "\n",
    "# R12 and not I predictions\n",
    "example_prediction_1 = memory[\"LiTS_L\"][sample_step][sample_x, :, :] # 11/206 as an example image\n",
    "example_prediction_diff_1 = torch.sum(\n",
    "    torch.stack(\n",
    "        [(example_prediction_1 == x) for x in [8, 9, 12, 13]], \n",
    "        dim = -1\n",
    "        ), \n",
    "    dim = -1\n",
    "        ).to(torch.uint8).cpu().numpy()\n",
    "example_prediction_diff_1 = np.stack(\n",
    "    [\n",
    "        np.zeros_like(example_prediction_diff_1),\n",
    "        np.zeros_like(example_prediction_diff_1),\n",
    "        example_prediction_diff_1 * 255,\n",
    "        example_prediction_diff_1 * 100\n",
    "    ],\n",
    "    axis = -1\n",
    ")\n",
    "# I and not R12 predictions\n",
    "example_prediction_2 = memory[\"LiTS_L\"][sample_step][sample_x, :, :] # 11/206 as an example image\n",
    "example_prediction_diff_2 = torch.sum(\n",
    "    torch.stack(\n",
    "        [(example_prediction_2 == x) for x in [2, 3, 6, 7]], \n",
    "        dim = -1\n",
    "        ), \n",
    "    dim = -1\n",
    "        ).to(torch.uint8).cpu().numpy()\n",
    "example_prediction_diff_2 = np.stack(\n",
    "    [\n",
    "        example_prediction_diff_2 * 255,\n",
    "        example_prediction_diff_2 * 255,\n",
    "        np.zeros_like(example_prediction_diff_2),\n",
    "        example_prediction_diff_2 * 100\n",
    "    ],\n",
    "    axis = -1\n",
    ")\n",
    "plt.figure()\n",
    "plt.imshow(example_image[::-1, ::-1])\n",
    "plt.imshow(example_prediction_diff_1[::-1, ::-1, :])\n",
    "plt.imshow(example_prediction_diff_2[::-1, ::-1, :])\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(f\"./figures/wkw_{group}_{sample_step}_{sample_x}_diff.png\", dpi = 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MEDDL_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
